{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### TMA4205 Numerical Linear Algebra\n",
    "# Project Part 2\n",
    "## Introduction\n",
    "\n",
    "In this part we want to find a low rank continuous approximation to a continuous matrix valued function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports and useful functions\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "# line cyclers adapted to colourblind people\n",
    "from cycler import cycler\n",
    "\n",
    "line_cycler = (cycler(color=[\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"]) +\n",
    "               cycler(linestyle=[\"-\", \"--\", \"-.\", \":\", \"-\", \"--\", \"-.\"]))\n",
    "plt.rc(\"axes\", prop_cycle=line_cycler)\n",
    "plt.rc('axes', axisbelow=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"First define some useful functions for plotting and testing\"\"\"\n",
    "from linalg.plotting import *\n",
    "from linalg.helpers import get_function_timings, truncated_svd, get_equidistant_indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1:\n",
    "We implement Lanczos bidiagonalization method with and without re-orthogonalization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from linalg.bidiagonalization import lanczos_bidiag, lanczos_bidiag_reorth, make_bidiagonal, get_bidiagonal_approx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make 3 randomly generated matrices $A_n \\in \\mathbb{R}^{n\\times n} $, $n \\in [32,64,128]$.\n",
    "Then we show their eigenvalues."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make matrices\n",
    "n_list = [32, 64, 128]\n",
    "A_list = [np.random.rand(n, n) * 2 - 1 for n in n_list]\n",
    "\n",
    "# plot their eigenvalues\n",
    "fig, axs = plt.subplots(ncols=len(n_list), sharey=True, constrained_layout=True, figsize=(3 * len(n_list) + 1, 4))\n",
    "fig.suptitle(\"Singular values of $A$\")\n",
    "for A, ax, n in zip(A_list, axs, n_list):\n",
    "    svs = np.linalg.svd(A, compute_uv=False)\n",
    "    ax.plot(svs, \".\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_xlabel(\"$\\sigma$ number\")\n",
    "    ax.set_title(f\"$n={n}$\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we approximate the matrix $A_n$ with different approximation methods.\n",
    "The truncated SVD gives the best approximation matrix of rank $k \\leq$ (in Frobenius norm).\n",
    "For all $k \\leq n$ compare the best approximation with Lanczos bidiagonalization method, with and without re-orthogonalization.\n",
    "\n",
    "We also measure the orthogonality error with the method from [5]:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\eta(U) :=  ||I -U^T U||_F\n",
    "\\end{equation}\n",
    "\n",
    "For each $k$ we also show this error for bidiagonalization with and without reorthogonalization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from linalg.helpers import get_best_approx\n",
    "\n",
    "fig, axs = plt.subplots(ncols=len(n_list), tight_layout=True, figsize=(1 + 3 * len(n_list), 4))\n",
    "axs[0].set_ylabel(\"$||A - A_k||_F$\")\n",
    "fig.suptitle(\"Error approximation methods of rank $k$ \")\n",
    "\n",
    "orth_fig, orth_axs = plt.subplots(ncols=len(n_list), sharey=True, tight_layout=True, figsize=(1 + 3 * len(n_list), 4))\n",
    "orth_fig.suptitle(\"Orthogonalization error for bidiagonalization of rank $k$\")\n",
    "orth_axs[0].set_ylabel(\"$||I - Q^{T}Q||_F$\")\n",
    "for A, n, ax, orth_ax in zip(A_list, n_list, axs, orth_axs):\n",
    "    best_approx_error = np.zeros(n)\n",
    "    bidiagonal_error = np.zeros(n)\n",
    "    bidiagonal_reorth_error = np.zeros(n)\n",
    "\n",
    "    # error: [P, Q, P_reorth, Q_reorth]\n",
    "    reorth_error = np.zeros((n, 4))\n",
    "\n",
    "    k_list = np.arange(1, n + 1)\n",
    "    for i, k in enumerate(range(1, n + 1)):\n",
    "        b = np.random.rand(n)\n",
    "        P, Q, alpha, beta = lanczos_bidiag(A, k, b)\n",
    "        B = make_bidiagonal(alpha, beta)\n",
    "        bidiagonal_error[i] = np.linalg.norm(A - P @ B @ Q.T, ord=\"fro\")\n",
    "        reorth_error[i, 0] = np.linalg.norm(np.eye(k) - P.T @ P, ord=\"fro\")\n",
    "        reorth_error[i, 1] = np.linalg.norm(np.eye(k) - Q.T @ Q, ord=\"fro\")\n",
    "\n",
    "        P, Q, alpha, beta = lanczos_bidiag_reorth(A, k, b)\n",
    "        B = make_bidiagonal(alpha, beta)\n",
    "        bidiagonal_reorth_error[i] = np.linalg.norm(A - P @ B @ Q.T, ord=\"fro\")\n",
    "        reorth_error[i, 2] = np.linalg.norm(np.eye(k) - P.T @ P, ord=\"fro\")\n",
    "        reorth_error[i, 3] = np.linalg.norm(np.eye(k) - Q.T @ Q, ord=\"fro\")\n",
    "\n",
    "        A_k = get_best_approx(A, k)\n",
    "        best_approx_error[i] = np.linalg.norm(A - A_k, ord=\"fro\")\n",
    "\n",
    "    ax.plot(k_list, best_approx_error, label=\"best approximation\")\n",
    "    ax.plot(k_list, bidiagonal_error, label=\"bidiagonalization\")\n",
    "    ax.plot(k_list, bidiagonal_reorth_error, label=\"bidiag. with reorth.\")\n",
    "    ax.set_xlabel(\"$k$\")\n",
    "    ax.set_title(f\"$n={n}$\")\n",
    "    ax.legend()\n",
    "\n",
    "    #plot orthogonality error\n",
    "    orth_ax.semilogy(k_list, reorth_error[:, 0], label=\"P\")\n",
    "    orth_ax.semilogy(k_list, reorth_error[:, 1], label=\"Q\")\n",
    "    orth_ax.semilogy(k_list, reorth_error[:, 2], label=\"P with reorth.\")\n",
    "    orth_ax.semilogy(k_list, reorth_error[:, 3], label=\"Q with reorth.\")\n",
    "    orth_ax.set_xlabel(\"$k$\")\n",
    "    orth_ax.set_title(f\"$n={n}$\")\n",
    "    orth_ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "From figures above we see that bidiagonalization without re-orthogonalization does not give good approximations for large $k$.\n",
    "The reason for this is that numerical instability makes the columns of $Q$ and $P$ not orthonormal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2\n",
    "In the following code block the integration method of order 2 is implemented.\n",
    "A method of order 1 is also used to obtain an estimate for the local truncation error.\n",
    "The step size is then determined based on this local truncation error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from linalg.integrate import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make sure that the resulting matrices are in fact orthogonal we take steps in using the caylay-map.\n",
    "Furthermore, all inputs in they caylay map are given on the form $B = [F, -U] [U, F]^T$.\n",
    "Where $U^TU = I$ and $F^T U=0$\n",
    "This input form we can exploit to compute the caylay map more efficiently:\n",
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from linalg.cayley_map import cayley_map_simple, cayley_map_plus, cayley_map_efficient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now compare the performance of the different ways to compute the caylay map.\n",
    "The cases are constructed by first generating matrices $A$ and $B$.\n",
    "$A$ and $B$ are random matrices with elements randomly drawn from the uniform distribution on [0,1].\n",
    "Then we compute the QR factorization of $A$ and set $Q$ as the $U$ matrix.\n",
    "Then $F$ is computed as $F:=(I - U U^T)G $"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from test.test_caylay import get_FUCDB\n",
    "\n",
    "m_list = 2 ** np.array([4, 5, 6, 7, 8, 9, 10, 11])\n",
    "sample_FUCDB = [get_FUCDB(m, k=int(np.sqrt(m))) for m in m_list]\n",
    "sample_FU = [(F, U) for F, U, C, D, B in sample_FUCDB]\n",
    "sample_CD = [(C, D) for F, U, C, D, B in sample_FUCDB]\n",
    "sample_B = [(B,) for F, U, C, D, B in sample_FUCDB]\n",
    "\n",
    "time_simple = get_function_timings(cayley_map_simple, sample_B, number=10)\n",
    "time_efficient = get_function_timings(cayley_map_efficient, sample_CD, number=10)\n",
    "time_plus = get_function_timings(cayley_map_plus, sample_FU, number=10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"Performance of different methods of caylay map computation\")\n",
    "ax.loglog(m_list, time_simple, label=\"simple\", base=2)\n",
    "ax.loglog(m_list, time_efficient, label=\"efficient\", base=2)\n",
    "ax.loglog(m_list, time_plus, label=\"efficient modified\", base=2)\n",
    "\n",
    "ax.set_ylabel(\"Time [ms]\")\n",
    "ax.set_xlabel(\"$m$\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that method caylay map implementation inverting the smallest matrix is the most efficient implementaiton for our case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now implement a space discretization of the heat equation as a matrix ode $\\dot A(t) =BA(t)$, with solution\n",
    "$A(t) = \\exp{tB}A(0)$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from test.case_matrix_ode import generate_heat_equation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now test our ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = 20\n",
    "t_f = 1\n",
    "k_list = [5, 15]\n",
    "fig, axs = plt.subplots(ncols=len(k_list), sharex=True, sharey=True, constrained_layout=True,\n",
    "                        figsize=(1 + 3 * len(k_list), 4))\n",
    "axs[0].set_ylabel(\"Frobenious norm\")\n",
    "fig.suptitle(\"Error for different low rank approximations\")\n",
    "\n",
    "for i, k in enumerate(k_list):\n",
    "    print(f\"Running k={k}\")\n",
    "    # generate case and start conditions\n",
    "    A_0, A, A_dot = generate_heat_equation(n=m, m=m, k=k)\n",
    "    Y_0 = truncated_svd(A_0, k)\n",
    "\n",
    "    # integrate\n",
    "    Y, T = matrix_ode_simple(0, t_f, Y_0=Y_0, X=A_dot, TOL=1e-3, verbose=True)\n",
    "    t_ind = get_equidistant_indexes(T, 0, t_f)\n",
    "    T = [T[i] for i in t_ind]\n",
    "    Y = [Y[i] for i in t_ind]\n",
    "\n",
    "    XA_diff = [np.linalg.norm(get_best_approx(A(t), k) - A(t), ord=\"fro\") for t in T]\n",
    "    YA_diff = [np.linalg.norm(multiply_factorized(*y) - A(t), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "    YX_diff = [np.linalg.norm(multiply_factorized(*y) - get_best_approx(A(t), k), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.set_title(f\"$k={k}$\")\n",
    "    ax.plot(T, XA_diff, label=\"||X - A||\")\n",
    "    ax.plot(T, YA_diff, label=\"||Y - A||\")\n",
    "    ax.plot(T, YX_diff, label=\"||Y - X||\")\n",
    "    ax.set_xlabel(\"$t$\")\n",
    "    ax.legend()\n",
    "    clear_output()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the best approximation of rank $k$ will perfectly approximate A wich also has rank $k$.\n",
    "$Y$ does not approximate as well as the best approximate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 3\n",
    "We now implement the test problem 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from test.case_matrix_ode import generate_first_example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now test our  solution on ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_f = 1\n",
    "eps_list = 10. ** np.array([-1, -2, -3, -4, -5])\n",
    "k_list = [10, 20]\n",
    "m = 100\n",
    "fig, axs = plt.subplots(nrows=len(eps_list), ncols=len(k_list), sharex=True, squeeze=False, constrained_layout=True,\n",
    "                        figsize=(1 + 3 * len(k_list), 1 + 3 * len(eps_list)))\n",
    "\n",
    "fig.suptitle(\"Error for different low rank approximations\")\n",
    "for i, eps in enumerate(eps_list):\n",
    "    axs[i, 0].set_ylabel(\"Frobenious norm\")\n",
    "    for j, k in enumerate(k_list):\n",
    "        axs[-1, j].set_xlabel(\"$t$\")\n",
    "        # generate case and start conditions\n",
    "        print(f\"k: {k}, epsilon: {eps}\")\n",
    "        A_0, A, A_dot = generate_first_example(eps=eps)\n",
    "        Y_0 = truncated_svd(A_0, k)\n",
    "\n",
    "        # integrate\n",
    "        Y, T = matrix_ode_simple(0, t_f, Y_0=Y_0, X=A_dot, TOL=1e-0, verbose=True)\n",
    "\n",
    "        t_ind = get_equidistant_indexes(T, 0, t_f)\n",
    "        T = [T[i] for i in t_ind]\n",
    "        Y = [Y[i] for i in t_ind]\n",
    "\n",
    "        # I know this is not the most efficient way but it is easy to read\n",
    "        b = np.random.rand(m)\n",
    "        XA_diff = [np.linalg.norm(get_best_approx(A(t), k) - A(t), ord=\"fro\") for t in T]\n",
    "        YA_diff = [np.linalg.norm(multiply_factorized(*y) - A(t), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "        WA_diff = [np.linalg.norm(get_bidiagonal_approx(A(t), k=k, b=b) - A(t), ord=\"fro\") for t in T]\n",
    "        YX_diff = [np.linalg.norm(multiply_factorized(*y) - get_best_approx(A(t), k), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "        ax = axs[i, j]\n",
    "        ax.set_title(f\"$k=${k}, $\\epsilon =$ {eps}\")\n",
    "        ax.plot(T, XA_diff, label=\"||X - A||\")\n",
    "        ax.plot(T, YA_diff, label=\"||Y - A||\")\n",
    "        ax.plot(T, WA_diff, label=\"||W - A||\")\n",
    "        ax.plot(T, YX_diff, label=\"||Y - X||\")\n",
    "        ax.legend()\n",
    "        clear_output()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see something..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4\n",
    "We now implement the test problem 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from test.case_matrix_ode import generate_second_example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now test our  solution on ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "t_f = 10\n",
    "eps_list = [1e-1]\n",
    "k_list = [5, 20]\n",
    "m = 100\n",
    "fig_sigma, axs_sigma = plt.subplots(nrows=len(eps_list), ncols=len(k_list), sharex=True, squeeze=False,\n",
    "                                    constrained_layout=True,\n",
    "                                    figsize=(1 + 3 * len(k_list), 1 + 3 * len(eps_list)))\n",
    "fig_sigma.suptitle(\"Singular values over time\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(eps_list), ncols=len(k_list), sharex=True, squeeze=False, constrained_layout=True,\n",
    "                        figsize=(1 + 3 * len(k_list), 1 + 3 * len(eps_list)))\n",
    "fig.suptitle(\"Error for different low rank approximations\")\n",
    "for i, eps in enumerate(eps_list):\n",
    "    axs[i, 0].set_ylabel(\"Frobenious norm\")\n",
    "    for j, k in enumerate(k_list):\n",
    "        axs[-1, j].set_xlabel(\"$t$\")\n",
    "        axs_sigma[-1, j].set_xlabel(\"$t$\")\n",
    "        # generate case and start conditions\n",
    "        print(f\"k: {k}, epsilon: {eps}\")\n",
    "        A_0, A, A_dot = generate_second_example(eps=eps)\n",
    "        Y_0 = truncated_svd(A_0, k)\n",
    "        # integrate\n",
    "        Y, T = matrix_ode_simple(0, t_f, Y_0=Y_0, X=A_dot, TOL=1e-5, h_0=1e-7, verbose=True)\n",
    "\n",
    "        # store a subset instead\n",
    "        t_ind = get_equidistant_indexes(T, 0, t_f)\n",
    "        T = [T[i] for i in t_ind]\n",
    "        Y = [Y[i] for i in t_ind]\n",
    "\n",
    "        # I know this is not the most efficient way but it is easy to read\n",
    "        b = np.random.rand(m)\n",
    "        XA_diff = [np.linalg.norm(get_best_approx(A(t), k) - A(t), ord=\"fro\") for t in T]\n",
    "        YA_diff = [np.linalg.norm(multiply_factorized(*y) - A(t), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "        WA_diff = [np.linalg.norm(get_bidiagonal_approx(A(t), k=k, b=b) - A(t), ord=\"fro\") for t in T]\n",
    "        YX_diff = [np.linalg.norm(multiply_factorized(*y) - get_best_approx(A(t), k), ord=\"fro\") for t, y in zip(T, Y)]\n",
    "        A_norm = np.array([np.linalg.norm(A(t), ord=\"fro\") for t in T])\n",
    "        ax = axs[i, j]\n",
    "        ax.set_title(f\"$k=${k}, $\\epsilon =$ {eps}\")\n",
    "        ax.plot(T, XA_diff / A_norm, label=\"||X - A||\")\n",
    "        ax.plot(T, YA_diff / A_norm, label=\"||Y - A||\")\n",
    "        ax.plot(T, WA_diff / A_norm, label=\"||W - A||\")\n",
    "        ax.plot(T, YX_diff / A_norm, label=\"||Y - X||\")\n",
    "        ax.legend()\n",
    "\n",
    "        sing_values = np.linalg.svd([A(t) for t in T], compute_uv=False)\n",
    "        sing_values_y = np.linalg.svd([S for U, S, V in Y], compute_uv=False)\n",
    "        ax_sigma = axs_sigma[i, j]\n",
    "        ax_sigma.set_title(f\"$k=${k}, $\\epsilon =$ {eps}\")\n",
    "        ax_sigma.plot(T, sing_values[:, :k], \"k-\", lw=0.5, label=\"A(t)\")\n",
    "        ax_sigma.plot(T[::2], sing_values_y[::2, :k], \"k.\", lw=0.5, label=\"Y(t)\")\n",
    "\n",
    "        clear_output()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot singular values, we can here use only $S$ since $Y$ is $S$ tranformed by unitary matricies.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = 0.8\n",
    "eps = 0.1\n",
    "A_0, A, A_dot = generate_second_example(eps=eps)\n",
    "plt.plot(np.linalg.svd(A(t), full_matrices=False, compute_uv=False)[:20])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "insert\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "insert"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}